{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mở trình duyệt Google Chrome ở trang thái Tab ẩn danh\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument(\"--start-maximized\")\n",
    "s = Service('C:\\chromedriver')\n",
    "driver = webdriver.Chrome(service=s, options=options)\n",
    "driver.implicitly_wait(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List tất cả url movie\n",
    "list_all_url_movie = pd.read_csv('E:/Crawl_Web/Rotten Tomatoes/Crawl URL/URL_movie.csv').squeeze('columns').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie = []\n",
    "\n",
    "for url_movie in list_all_url_movie:\n",
    "    try:\n",
    "        # Mở url phim\n",
    "        driver.get(url_movie)\n",
    "        \n",
    "        # Đợi cho đến khi url load xong\n",
    "        element = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'main[id=\"main_container\"]')))\n",
    "        html_of_interest = driver.execute_script('return arguments[0].innerHTML',element)\n",
    "        soup = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "        ## Tạo Dict chứa thông tin về phim\n",
    "        dict_info_movie = {}\n",
    "\n",
    "        # Tiêu đề phim\n",
    "        dict_info_movie['Title'] = soup.select('h1[class=\"scoreboard__title\"]')[0].text\n",
    "\n",
    "        # Điểm đánh giá của nhà phê bình\n",
    "        tomatometer = soup.select('score-board')[0].attrs['tomatometerscore']\n",
    "        dict_info_movie['Tomatometer score'] = tomatometer\n",
    "\n",
    "        # Điểm đánh giá của khán giả\n",
    "        dict_info_movie['Audience score'] = soup.select('score-board')[0].attrs['audiencescore']\n",
    "\n",
    "        # Số lượt đánh giá của nhà phê bình\n",
    "        dict_info_movie['Tomatometer count'] = soup.select('a[slot=\"critics-count\"]')[0].text.strip()\n",
    "\n",
    "        # Số lượt đánh giá của khán giả\n",
    "        dict_info_movie['Audience count'] = soup.select('a[slot=\"audience-count\"]')[0].text.strip()\n",
    "\n",
    "        # Trạng thái đánh giá phim của nhà phê bình\n",
    "        dict_info_movie['Tomatometer state'] = soup.select('score-board')[0].attrs['tomatometerstate']\n",
    "\n",
    "        # Trạng thái đánh giá phim của khán giả\n",
    "        dict_info_movie['Audience state'] = soup.select('score-board')[0].attrs['audiencestate']\n",
    "\n",
    "        # Thông tin phim\n",
    "        list_name_info = soup.select('b[class=\"info-item-label\"]')\n",
    "        list_info = soup.select('span[data-qa=\"movie-info-item-value\"]')\n",
    "\n",
    "        for num_info in range(len(list_name_info)):\n",
    "            name_info = list_name_info[num_info].text.replace('  ', '').replace('\\n', '').replace(':', '')\n",
    "            info = list_info[num_info].text.replace('  ', '').replace('\\n', '').replace(':', '')\n",
    "            dict_info_movie[name_info] = info\n",
    "\n",
    "        # Tóm tắt nội dụng phim\n",
    "        dict_info_movie['Synopsis'] = soup.select('p[data-qa=\"movie-info-synopsis\"]')[0].text.strip()\n",
    "\n",
    "        # Diễn viên\n",
    "        list_raw_cast = soup.select('a[data-qa=\"cast-crew-item-link\"] > p')\n",
    "        list_cast = []\n",
    "\n",
    "        for c in range(len(list_raw_cast)):\n",
    "            list_cast.append(list_raw_cast[c].text)\n",
    "\n",
    "        dict_info_movie['Cast'] = ', '.join(list_cast)\n",
    "\n",
    "        df_movie.append(dict_info_movie)\n",
    "\n",
    "        # Reviews của nhà phê bình\n",
    "        driver.get(url_movie + '/reviews')\n",
    "\n",
    "        element_critic_review = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[class=\"layout reviews-page-container\"]')))\n",
    "        html_of_interest = driver.execute_script('return arguments[0].innerHTML',element_critic_review)\n",
    "        soup_critic_review = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "        # Check có review của nhà phê bình không ?\n",
    "        check_critic_review = soup_critic_review.select('div[class=\"review_table\"]')[0].text.strip()\n",
    "\n",
    "        if check_critic_review != '':\n",
    "            list_critic_review = []\n",
    "            list_top_critic_review = []\n",
    "            \n",
    "            # Số lượng review trong 1 trang\n",
    "            num_rv = len(soup_critic_review.select('div[class=\"review-row\"]'))\n",
    "\n",
    "            for num in range(num_rv):\n",
    "                rv = soup_critic_review.select('div[class=\"review-row\"]')[num].find_all('p', {'class': 'review-text'})[0].text\n",
    "                list_critic_review.append(rv)\n",
    "\n",
    "                # Check top critic reviews\n",
    "                check_top_critic = soup_critic_review.select('div[class=\"review-row\"]')[num].find_all('rt-icon-top-critic')\n",
    "\n",
    "                if check_top_critic != []:\n",
    "                    list_top_critic_review.append(rv)\n",
    "            \n",
    "            while True:\n",
    "                sleep(1)\n",
    "                try:\n",
    "                    next_button = driver.find_element(By.CSS_SELECTOR, 'rt-button[class=\"js-prev-next-paging-next\"]')\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    \n",
    "                    element_critic_review = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[class=\"review_table\"]')))\n",
    "                    html_of_interest = driver.execute_script('return arguments[0].innerHTML',element_critic_review)\n",
    "                    soup_critic_review = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "                    num_rv = len(soup_critic_review.select('div[class=\"review-row\"]'))\n",
    "\n",
    "                    for num in range(num_rv):\n",
    "                        rv = soup_critic_review.select('div[class=\"review-row\"]')[num].find_all('p', {'class': 'review-text'})[0].text.strip()\n",
    "                        list_critic_review.append(rv)\n",
    "\n",
    "                        check_top_critic = soup_critic_review.select('div[class=\"review-row\"]')[num].find_all('rt-icon-top-critic')\n",
    "\n",
    "                        if check_top_critic != []:\n",
    "                            list_top_critic_review.append(rv)\n",
    "                    \n",
    "                except:\n",
    "                    break\n",
    "            dict_info_movie['Critic review'] = '<>'.join(list_critic_review)\n",
    "            if list_top_critic_review != []:\n",
    "                dict_info_movie['Top critic review'] = '<>'.join(list_top_critic_review)\n",
    "            else:\n",
    "                dict_info_movie['Top critic review'] = 'No top critic reviews'\n",
    "        elif check_critic_review == '':\n",
    "            dict_info_movie['Critic review'] = 'No critic reviews'\n",
    "            dict_info_movie['Top critic review'] = 'No top critic reviews'\n",
    "\n",
    "        # Reviews của khán giả\n",
    "        driver.get(url_movie + '/reviews?type=user')\n",
    "\n",
    "        element_audience_review = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-qa=\"reviews-container\"]')))\n",
    "        html_of_interest = driver.execute_script('return arguments[0].innerHTML',element_audience_review)\n",
    "        soup_audience_review = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "        ## Check có review của khán giả không ?\n",
    "        check_audience_review = soup_audience_review.select('div[id=\"movieUserReviewsContent\"]')\n",
    "\n",
    "        if len(check_audience_review) != 0:\n",
    "            list_audience_review = []\n",
    "            list_verified_audience_review = []\n",
    "            \n",
    "            # Số lượng review trong 1 trang\n",
    "            num_audience_rv = len(soup_audience_review.select('div[class=\"audience-review-row\"]'))\n",
    "            \n",
    "            for num in range(num_audience_rv):\n",
    "                rv = soup_audience_review.select('div[class=\"audience-review-row\"]')[num].find_all('p', {'data-qa': 'review-text'})[0].text\n",
    "                list_audience_review.append(rv)\n",
    "\n",
    "                # Check verified audience review\n",
    "                check_verified_audience = soup_audience_review.select('div[class=\"audience-review-row\"]')[num].find_all('span', {'class': 'audience-reviews__verified'})\n",
    "\n",
    "                if check_verified_audience != []:\n",
    "                    list_verified_audience_review.append(rv)\n",
    "            \n",
    "            while True:\n",
    "                sleep(1)\n",
    "                try:\n",
    "                    next_button = driver.find_element(By.CSS_SELECTOR, 'rt-button[class=\"js-prev-next-paging-next\"]')\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    \n",
    "                    element_audience_review = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[id=\"movieUserReviewsContent\"]')))\n",
    "                    html_of_interest = driver.execute_script('return arguments[0].innerHTML',element_audience_review)\n",
    "                    soup_audience_review = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "                    # Số lượng review trong 1 trang\n",
    "                    num_audience_rv = len(soup_audience_review.select('div[class=\"audience-review-row\"]'))\n",
    "                    \n",
    "                    for num in range(num_audience_rv):\n",
    "                        rv = soup_audience_review.select('div[class=\"audience-review-row\"]')[num].find_all('p', {'data-qa': 'review-text'})[0].text\n",
    "                        list_audience_review.append(rv)\n",
    "\n",
    "                        # Check verified audience review\n",
    "                        check_verified_audience = soup_audience_review.select('div[class=\"audience-review-row\"]')[num].find_all('span', {'class': 'audience-reviews__verified'})\n",
    "\n",
    "                        if check_verified_audience != []:\n",
    "                            list_verified_audience_review.append(rv)\n",
    "                    \n",
    "                except:\n",
    "                    break\n",
    "            dict_info_movie['Audience review'] = '<>'.join(list_audience_review)\n",
    "            if list_verified_audience_review != []:\n",
    "                dict_info_movie['Verified audience review'] = '<>'.join(list_verified_audience_review)\n",
    "            else:\n",
    "                dict_info_movie['Verified audience review'] = 'No verified audience reviews'\n",
    "\n",
    "        else:\n",
    "            dict_info_movie['Audience review'] = 'No audience reviews'\n",
    "            dict_info_movie['Verified audience review'] = 'No verified audience reviews'\n",
    "\n",
    "        df_movie.append(dict_info_movie)\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "    \n",
    "df_movie = pd.DataFrame(df_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie.to_csv('movie_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
